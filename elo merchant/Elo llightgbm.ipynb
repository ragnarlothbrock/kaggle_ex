{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general workflow is:\n",
    "\n",
    "* Fill NaN with most common value for that column\n",
    "* Take the historical / new files, aggregate each column using min, mean, max, standard deviation, count. (including categorical variables which proved to be important)\n",
    "* A good chunk of the train dataset doesn't have rows for the new files but lightgbm can handle this. I use a StratifiedKFold of 5 folds to help smooth out predictions for test set.\n",
    "* Important note for CV vs LB which I learned in the Kaggle forums: drop the columns that don't have a similar distribution of values between the train and test files. This will cause your predictions on test to be well-prepared by the train data set.\n",
    "* The features that stand out the most are the ones that represent how much they paid and when they committed those transactions. I've tried layering on more features as this competition has gone on and some of them have added value to my score.\n",
    "* There's a LOT of crazy outliers (10x standard deviations -> -31 value) that obviously blow out the end RMSE. If I train just on the non-outliers, my score is in the mid 1's (1.4 ish), but since we have to predict these outliers too, it gets blown out to 3.735. Whoever can best predict outliers will win this competition, plain and simple. I tried out doing a classifier on whether we could predict if an outlier exists, but it didn't help my end RMSE (even though the AUC was ~.8). Curious if anyone had success adding a classifier on the -31 outliers.\n",
    "In addition a challenge for this dataset was the size of the data using 16GB of RAM on Kaggle environment. Just importing the data takes >1 minute. I used some tactics like pandas .sample() to more efficiently move the data through the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "import datetime\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1749.11 Mb (43.7% reduction)\n",
      "Mem. usage decreased to  4.04 Mb (56.2% reduction)\n",
      "Mem. usage decreased to  2.24 Mb (52.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "historical_transactions = reduce_mem_usage(pd.read_csv('historical_transactions.csv'))\n",
    "train = reduce_mem_usage(pd.read_csv('train.csv'))\n",
    "test = reduce_mem_usage(pd.read_csv('test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transx = pd.merge(\n",
    "    historical_transactions,\n",
    "    train['card_id'].to_frame(),\n",
    "    on = 'card_id',\n",
    "    how = 'inner'\n",
    ")\n",
    "\n",
    "test_transx = pd.merge(\n",
    "    test['card_id'].to_frame(),\n",
    "    historical_transactions,\n",
    "    on = 'card_id',\n",
    "    how = 'inner'\n",
    ")\n",
    "\n",
    "del historical_transactions\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# historical_transactions clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>card_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>category_3</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>category_2</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subsector_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>C_ID_5037ff576e</td>\n",
       "      <td>322</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>278</td>\n",
       "      <td>M_ID_b61c7d1be0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.595260</td>\n",
       "      <td>2017-09-07 20:57:19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_5037ff576e</td>\n",
       "      <td>138</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>307</td>\n",
       "      <td>M_ID_fe69229f24</td>\n",
       "      <td>-4</td>\n",
       "      <td>1.189469</td>\n",
       "      <td>2017-08-14 15:46:08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_5037ff576e</td>\n",
       "      <td>138</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>705</td>\n",
       "      <td>M_ID_efc106141c</td>\n",
       "      <td>-9</td>\n",
       "      <td>-0.640069</td>\n",
       "      <td>2017-03-05 14:57:51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_5037ff576e</td>\n",
       "      <td>226</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>307</td>\n",
       "      <td>M_ID_708022307c</td>\n",
       "      <td>-4</td>\n",
       "      <td>-0.652256</td>\n",
       "      <td>2017-08-15 10:45:28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_5037ff576e</td>\n",
       "      <td>330</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>705</td>\n",
       "      <td>M_ID_393b4b8cec</td>\n",
       "      <td>-9</td>\n",
       "      <td>-0.674210</td>\n",
       "      <td>2017-03-26 20:00:31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  authorized_flag          card_id  city_id category_1  installments  \\\n",
       "0               N  C_ID_5037ff576e      322          N             1   \n",
       "1               Y  C_ID_5037ff576e      138          N             1   \n",
       "2               Y  C_ID_5037ff576e      138          N             1   \n",
       "3               Y  C_ID_5037ff576e      226          N             1   \n",
       "4               Y  C_ID_5037ff576e      330          N             1   \n",
       "\n",
       "  category_3  merchant_category_id      merchant_id  month_lag  \\\n",
       "0          B                   278  M_ID_b61c7d1be0         -3   \n",
       "1          B                   307  M_ID_fe69229f24         -4   \n",
       "2          B                   705  M_ID_efc106141c         -9   \n",
       "3          B                   307  M_ID_708022307c         -4   \n",
       "4          B                   705  M_ID_393b4b8cec         -9   \n",
       "\n",
       "   purchase_amount        purchase_date  category_2  state_id  subsector_id  \n",
       "0        -0.595260  2017-09-07 20:57:19         3.0        11            37  \n",
       "1         1.189469  2017-08-14 15:46:08         1.0        15            19  \n",
       "2        -0.640069  2017-03-05 14:57:51         1.0        15            33  \n",
       "3        -0.652256  2017-08-15 10:45:28         1.0        16            19  \n",
       "4        -0.674210  2017-03-26 20:00:31         3.0        17            33  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "transx['nan_merchant_id'] = 0\n",
    "transx.loc[transx.merchant_id.isnull(), 'nan_merchant_id'] = 1\n",
    "transx.loc[transx.merchant_id.isnull(), 'merchant_id'] == 'M_ID_00a6ca8a8a'\n",
    "\n",
    "transx['nan_category_3'] = 0\n",
    "transx.loc[transx.category_3.isnull(), 'nan_category_3'] = 1\n",
    "transx.loc[transx.category_3.isnull(), 'category_3'] = 'A'\n",
    "\n",
    "transx['nan_category_2'] = 0\n",
    "transx.loc[transx.category_2.isnull(), 'nan_category_2'] = 1\n",
    "transx.loc[transx.category_2.isnull(), 'category_2'] = 1.0\n",
    "\n",
    "transx['category_1'] = transx['category_1'].map({'Y': 1, 'N': 0})\n",
    "transx['authorized_flag'] = transx['authorized_flag'].map({'Y': 1, 'N': 0})\n",
    "transx['category_3'] = transx['category_3'].map({'A': 0, 'B': 1, 'C': 2})\n",
    "\n",
    "transx['exec_date'] = pd.to_datetime(transx['purchase_date'], format = '%Y%m%d %H:%M:%S')\n",
    "transx['month'] = transx['exec_date'].dt.month\n",
    "transx['year'] = transx['exec_date'].dt.year\n",
    "transx['day'] = transx['exec_date'].dt.day\n",
    "transx['day_of_year'] = transx['exec_date'].dt.dayofyear\n",
    "transx['day_of_week'] = transx['exec_date'].dt.dayofweek\n",
    "transx['is_month_start'] = (transx['exec_date'].dt.is_month_start).astype(int)\n",
    "transx['is_month_end'] = (transx['exec_date'].dt.is_month_end).astype(int)\n",
    "transx['is_weekend'] = (transx['exec_date'].dt.dayofweek >= 5).astype(int)\n",
    "transx['is_weekday'] = (transx['exec_date'].dt.dayofweek < 5).astype(int)\n",
    "transx['weekday'] = transx['exec_date'].dt.weekday\n",
    "transx['week_of_year'] = transx['exec_date'].dt.weekofyear\n",
    "transx['days_since_purchase'] = (datetime.datetime.today() - transx['exec_date']).dt.days\n",
    "transx['quarter'] = transx['exec_date'].dt.quarter\n",
    "transx['hour'] = transx['exec_date'].dt.hour\n",
    "transx['months_since_purchase'] = (((datetime.datetime.today() - transx['exec_date']).dt.days)/30) + transx['month_lag']\n",
    "transx['duration'] = transx['purchase_amount'] * transx['months_since_purchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transx['nan_merchant_id'] = 0\n",
    "test_transx.loc[test_transx.merchant_id.isnull(), 'nan_merchant_id'] = 1\n",
    "test_transx.loc[test_transx.merchant_id.isnull(), 'merchant_id'] = 'M_ID_00a6ca8a8a'\n",
    "\n",
    "test_transx['nan_category_3'] = 0\n",
    "test_transx.loc[test_transx.category_3.isnull(), 'nan_category_3'] = 1\n",
    "test_transx.loc[test_transx.category_3.isnull(), 'category_3'] = 'A'\n",
    "\n",
    "test_transx['nan_category_2'] = 0\n",
    "test_transx.loc[test_transx.category_2.isnull(), 'nan_category_2'] = 1\n",
    "test_transx.loc[test_transx.category_2.isnull(), 'category_2'] = 1.0\n",
    "\n",
    "test_transx['category_1'] = test_transx['category_1'].map({'Y': 1, 'N': 0})\n",
    "test_transx['authorized_flag'] = test_transx['authorized_flag'].map({'Y': 1, 'N': 0})\n",
    "test_transx['category_3'] = test_transx['category_3'].map({'A': 0, 'B': 1, 'C': 2})\n",
    "\n",
    "test_transx['exec_date'] = pd.to_datetime(test_transx['purchase_date'], format = '%Y%m%d %H:%M:%S')\n",
    "test_transx['month'] = pd.DatetimeIndex(test_transx['exec_date']).month\n",
    "test_transx['year'] = pd.DatetimeIndex(test_transx['exec_date']).year\n",
    "test_transx['day'] = pd.DatetimeIndex(test_transx['exec_date']).day\n",
    "test_transx['day_of_year'] = pd.DatetimeIndex(test_transx['exec_date']).dayofyear\n",
    "test_transx['day_of_week'] = pd.DatetimeIndex(test_transx['exec_date']).dayofweek\n",
    "test_transx['is_month_start'] = (pd.DatetimeIndex(test_transx['exec_date']).is_month_start).astype(int)\n",
    "test_transx['is_month_end'] = (pd.DatetimeIndex(test_transx['exec_date']).is_month_end).astype(int)\n",
    "test_transx['is_weekend'] = (pd.DatetimeIndex(test_transx['exec_date']).dayofweek >= 5).astype(int)\n",
    "test_transx['is_weekday'] = (pd.DatetimeIndex(test_transx['exec_date']).dayofweek < 5).astype(int)\n",
    "test_transx['weekday'] = pd.DatetimeIndex(test_transx['exec_date']).weekday\n",
    "test_transx['week_of_year'] = pd.DatetimeIndex(test_transx['exec_date']).weekofyear\n",
    "test_transx['days_since_purchase'] = (datetime.datetime.today() - test_transx['exec_date']).dt.days\n",
    "test_transx['quarter'] = pd.DatetimeIndex(test_transx['exec_date']).quarter\n",
    "test_transx['hour'] = pd.DatetimeIndex(test_transx['exec_date']).hour\n",
    "test_transx['months_since_purchase'] = (((datetime.datetime.today() - test_transx['exec_date']).dt.days) / 30) + test_transx['month_lag']\n",
    "test_transx['duration'] = test_transx['purchase_amount'] * test_transx['months_since_purchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_inputs = {\n",
    "    'card_id' : ['nunique', 'size'],\n",
    "    'exec_date' : ['min', 'max'],\n",
    "    'city_id' : ['nunique'], \n",
    "    'installments' : ['mean', 'max', 'min', 'var', 'std', 'sum'],\n",
    "    'merchant_category_id' : ['nunique'], \n",
    "    'month_lag' : ['mean', 'max', 'min', 'var', 'std', 'sum'],\n",
    "    'purchase_amount' : ['mean', 'max', 'min', 'var', 'std', 'sum'], \n",
    "    'category_2': ['nunique', 'mean'],\n",
    "    'state_id' : ['nunique'],\n",
    "    'subsector_id' : ['nunique'], \n",
    "    'nan_merchant_id' : ['nunique', 'mean', 'sum'], \n",
    "    'nan_category_3': ['nunique', 'mean', 'sum'], \n",
    "    'nan_category_2': ['nunique', 'mean', 'sum'],\n",
    "    'authorized_flag': ['sum', 'mean'],\n",
    "    'category_1' : ['nunique', 'mean', 'sum'],\n",
    "    'category_3': ['nunique', 'mean', 'sum'],\n",
    "    'month': ['mean', 'max', 'min', 'var', 'std', 'nunique'], \n",
    "    'year': ['mean', 'max', 'min', 'var', 'std', 'nunique'], \n",
    "    'day': ['mean', 'max', 'min', 'var', 'std', 'nunique'], \n",
    "    'weekday': ['mean', 'max', 'min', 'var', 'std', 'nunique'], \n",
    "    'week_of_year': ['mean', 'max', 'min', 'var', 'std', 'nunique'],\n",
    "    'day_of_year': ['mean', 'max', 'min', 'var', 'std', 'nunique'],\n",
    "    'day_of_week': ['mean', 'max', 'min', 'var', 'std', 'nunique'],\n",
    "    'months_since_purchase' : ['mean', 'max', 'min', 'var', 'std', 'sum'],\n",
    "    'quarter' : ['mean', 'max', 'min', 'var', 'std', 'nunique'],\n",
    "    'hour' : ['mean', 'max', 'min', 'var', 'std', 'nunique'],\n",
    "    'is_month_start': ['mean', 'sum'],\n",
    "    'is_month_end': ['mean', 'sum'],\n",
    "    'is_weekend': ['mean', 'sum'],\n",
    "    'is_weekday': ['mean', 'sum'],\n",
    "    'duration' : ['mean', 'max', 'min', 'var', 'std', 'sum']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "transx_staging = transx[\n",
    "    [\n",
    "        'card_id', \n",
    "        'exec_date',\n",
    "        'city_id', \n",
    "        'installments',\n",
    "        'merchant_category_id', \n",
    "        'month_lag',\n",
    "        'purchase_amount', \n",
    "        'category_2', \n",
    "        'state_id',\n",
    "        'subsector_id', \n",
    "        'nan_merchant_id', \n",
    "        'nan_category_3', \n",
    "        'nan_category_2',\n",
    "        'authorized_flag',\n",
    "        'category_1',\n",
    "        'category_3', \n",
    "        'month', \n",
    "        'year', \n",
    "        'day', \n",
    "        'weekday', \n",
    "        'week_of_year',\n",
    "        'day_of_year',\n",
    "        'day_of_week',\n",
    "        'days_since_purchase',\n",
    "        'is_month_start',\n",
    "        'is_month_end',\n",
    "        'is_weekend',\n",
    "        'is_weekday',\n",
    "        'quarter',\n",
    "        'hour',\n",
    "        'months_since_purchase',\n",
    "        'duration'\n",
    "    ]\n",
    "]\n",
    "\n",
    "del transx\n",
    "gc.collect()\n",
    "\n",
    "transx_staging = transx_staging.groupby('card_id').agg(agg_inputs).reset_index()\n",
    "transx_staging.columns = ['h_t_' + '_'.join(col).strip() for col in transx_staging.columns.values]\n",
    "transx_staging = transx_staging.rename(columns={transx_staging.columns[0] : 'card_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transx_staging = test_transx[\n",
    "    [\n",
    "        'card_id',\n",
    "        'exec_date',\n",
    "        'city_id',\n",
    "        'installments',\n",
    "        'merchant_category_id', \n",
    "        'month_lag',\n",
    "        'purchase_amount', \n",
    "        'category_2', \n",
    "        'state_id',\n",
    "        'subsector_id', \n",
    "        'nan_merchant_id', \n",
    "        'nan_category_3', \n",
    "        'nan_category_2',\n",
    "        'authorized_flag',\n",
    "        'category_1',\n",
    "        'category_3', \n",
    "        'month', \n",
    "        'year', \n",
    "        'day', \n",
    "        'weekday', \n",
    "        'week_of_year',\n",
    "        'day_of_year',\n",
    "        'day_of_week',\n",
    "        'days_since_purchase',\n",
    "        'is_month_start',\n",
    "        'is_month_end',\n",
    "        'is_weekend',\n",
    "        'is_weekday',\n",
    "        'quarter',\n",
    "        'hour',\n",
    "        'months_since_purchase',\n",
    "        'duration'\n",
    "    ]\n",
    "]\n",
    "\n",
    "del test_transx\n",
    "gc.collect()\n",
    "\n",
    "test_transx_staging = test_transx_staging.groupby('card_id').agg(agg_inputs).reset_index()\n",
    "test_transx_staging.columns = ['h_t_' + '_'.join(col).strip() for col in test_transx_staging.columns.values]\n",
    "test_transx_staging = test_transx_staging.rename(columns={test_transx_staging.columns[0] : 'card_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.merge(train, transx_staging, on = 'card_id', how = 'left')\n",
    "\n",
    "train['first_purch'] = pd.to_datetime(train['first_active_month'], format = '%Y%m%d %H:%M:%S')\n",
    "train['first_month'] = train['first_purch'].dt.month\n",
    "train['first_year'] = train['first_purch'].dt.year\n",
    "train['days'] = train['first_purch'].dt.day\n",
    "train['first_quarter'] = train['first_purch'].dt.quarter\n",
    "train['first_week'] = train['first_purch'].dt.weekofyear\n",
    "train['first_day_of_week'] = train['first_purch'].dt.dayofweek\n",
    "\n",
    "train['days_feature1'] = train['days'] * train['feature_1']\n",
    "train['days_featire2'] = train['days'] * train['feature_2']\n",
    "train['days_feature3'] = train['days'] * train['feature_3']\n",
    "\n",
    "\n",
    "test = pd.merge(test, test_transx_staging, on = 'card_id', how = 'left')\n",
    "\n",
    "test['first_purch'] = pd.to_datetime(test['first_active_month'], format = '%Y%m%d %H:%M:%S')\n",
    "test['first_month'] = pd.DatetimeIndex(test['first_purch']).month\n",
    "test['first_year'] = pd.DatetimeIndex(test['first_purch']).year\n",
    "test['days'] = pd.DatetimeIndex(test['first_purch']).day\n",
    "test['first_quarter'] = pd.DatetimeIndex(test['first_purch']).quarter\n",
    "test['first_week'] = pd.DatetimeIndex(test['first_purch']).weekofyear\n",
    "test['first_day_of_week'] = pd.DatetimeIndex(test['first_purch']).dayofweek\n",
    "\n",
    "test['days_feature1'] = test['days'] * train['feature_1']\n",
    "test['days_feature2'] = test['days'] * train['feature_2']\n",
    "test['days_feature3'] = test['days'] * train['feature_3']\n",
    "\n",
    "del [\n",
    "    test_transx_staging,\n",
    "    transx_staging\n",
    "]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 114.20 Mb (45.5% reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_merchant_transactions = reduce_mem_usage(pd.read_csv('new_merchant_transactions.csv'))\n",
    "\n",
    "new_transx = pd.merge(new_merchant_transactions, train['card_id'].to_frame(), \n",
    "                     on = 'card_id', how = 'inner')\n",
    "\n",
    "test_new_transx = pd.merge(test['card_id'].to_frame(), new_merchant_transactions, \n",
    "                          on = 'card_id',\n",
    "                          how = 'inner')\n",
    "del new_merchant_transactions\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new_merchant_transactions clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transx['nan_merchant_id'] = 0\n",
    "new_transx.loc[new_transx.merchant_id.isnull(), 'nan_merchant_id'] = 1\n",
    "new_transx.loc[new_transx.merchant_id.isnull(), 'merchant_id'] = 'M_ID_00a6ca8a8a'\n",
    "\n",
    "new_transx['nan_category_3'] = 0\n",
    "new_transx.loc[new_transx.category_3.isnull(), 'nan_category_3'] = 1\n",
    "new_transx.loc[new_transx.category_3.isnull(), 'category_3'] = 'A'\n",
    "\n",
    "new_transx['nan_category_2'] = 0\n",
    "new_transx.loc[new_transx.category_2.isnull(), 'nan_category_2'] = 1\n",
    "new_transx.loc[new_transx.category_2.isnull(), 'category_2'] = 1.0\n",
    "\n",
    "new_transx['category_1'] = new_transx['category_1'].map({'Y': 1, 'N': 0})\n",
    "new_transx['authorized_flag'] = new_transx['authorized_flag'].map({'Y': 1, 'N': 0})\n",
    "new_transx['category_3'] = new_transx['category_3'].map({'A': 0, 'B': 1, 'C': 2})\n",
    "\n",
    "new_transx['exec_date'] = pd.to_datetime(new_transx['purchase_date'], format = '%Y%m%d %H:%M:%S')\n",
    "new_transx['month'] = pd.DatetimeIndex(new_transx['exec_date']).month\n",
    "new_transx['year'] = pd.DatetimeIndex(new_transx['exec_date']).year\n",
    "new_transx['day'] = pd.DatetimeIndex(new_transx['exec_date']).day\n",
    "new_transx['day_of_year'] = pd.DatetimeIndex(new_transx['exec_date']).dayofyear\n",
    "new_transx['day_of_week'] = pd.DatetimeIndex(new_transx['exec_date']).dayofweek\n",
    "new_transx['is_month_start'] = (pd.DatetimeIndex(new_transx['exec_date']).is_month_start).astype(int)\n",
    "new_transx['is_month_end'] = (pd.DatetimeIndex(new_transx['exec_date']).is_month_end).astype(int)\n",
    "new_transx['is_weekend'] = (pd.DatetimeIndex(new_transx['exec_date']).dayofweek >= 5).astype(int)\n",
    "new_transx['is_weekday'] = (pd.DatetimeIndex(new_transx['exec_date']).dayofweek < 5).astype(int)\n",
    "new_transx['weekday'] = pd.DatetimeIndex(new_transx['exec_date']).weekday\n",
    "new_transx['week_of_year'] = pd.DatetimeIndex(new_transx['exec_date']).weekofyear\n",
    "new_transx['quarter'] = pd.DatetimeIndex(new_transx['exec_date']).quarter\n",
    "new_transx['hour'] = pd.DatetimeIndex(new_transx['exec_date']).hour\n",
    "new_transx['days_since_purchase'] = (datetime.datetime.today() - new_transx['exec_date']).dt.days\n",
    "new_transx['months_since_purchase'] = (((datetime.datetime.today() - new_transx['exec_date']).dt.days) / 30) + new_transx['month_lag']\n",
    "new_transx['duration'] = new_transx['purchase_amount'] * new_transx['months_since_purchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new_transx['nan_merchant_id'] = 0\n",
    "test_new_transx.loc[test_new_transx.merchant_id.isnull(), 'nan_merchant_id'] = 1\n",
    "test_new_transx.loc[test_new_transx.merchant_id.isnull(), 'merchant_id'] = 'M_ID_00a6ca8a8a'\n",
    "\n",
    "test_new_transx['nan_category_3'] = 0\n",
    "test_new_transx.loc[test_new_transx.category_3.isnull(), 'nan_category_3'] = 1\n",
    "test_new_transx.loc[test_new_transx.category_3.isnull(), 'category_3'] = 'A'\n",
    "\n",
    "test_new_transx['nan_category_2'] = 0\n",
    "test_new_transx.loc[test_new_transx.category_2.isnull(), 'nan_category_2'] = 1\n",
    "test_new_transx.loc[test_new_transx.category_2.isnull(), 'category_2'] = 1.0\n",
    "\n",
    "test_new_transx['exec_date'] = pd.to_datetime(test_new_transx['purchase_date'], format = '%Y%m%d %H:%M:%S')\n",
    "test_new_transx['month'] = pd.DatetimeIndex(test_new_transx['exec_date']).month\n",
    "test_new_transx['year'] = pd.DatetimeIndex(test_new_transx['exec_date']).year\n",
    "test_new_transx['day'] = pd.DatetimeIndex(test_new_transx['exec_date']).day\n",
    "test_new_transx['day_of_year'] = pd.DatetimeIndex(test_new_transx['exec_date']).dayofyear\n",
    "test_new_transx['day_of_week'] = pd.DatetimeIndex(test_new_transx['exec_date']).dayofweek\n",
    "test_new_transx['is_month_start'] = (pd.DatetimeIndex(test_new_transx['exec_date']).is_month_start).astype(int)\n",
    "test_new_transx['is_month_end'] = (pd.DatetimeIndex(test_new_transx['exec_date']).is_month_end).astype(int)\n",
    "test_new_transx['is_weekend'] = (pd.DatetimeIndex(test_new_transx['exec_date']).dayofweek >= 5).astype(int)\n",
    "test_new_transx['is_weekday'] = (pd.DatetimeIndex(test_new_transx['exec_date']).dayofweek < 5).astype(int)\n",
    "test_new_transx['weekday'] = pd.DatetimeIndex(test_new_transx['exec_date']).weekday\n",
    "test_new_transx['week_of_year'] = pd.DatetimeIndex(test_new_transx['exec_date']).weekofyear\n",
    "test_new_transx['quarter'] = pd.DatetimeIndex(test_new_transx['exec_date']).quarter\n",
    "test_new_transx['hour'] = pd.DatetimeIndex(test_new_transx['exec_date']).hour\n",
    "test_new_transx['days_since_purchase'] = (datetime.datetime.today() - test_new_transx['exec_date']).dt.days\n",
    "test_new_transx['category_1'] = test_new_transx['category_1'].map({'Y': 1, 'N': 0})\n",
    "test_new_transx['authorized_flag'] = test_new_transx['authorized_flag'].map({'Y': 1, 'N': 0})\n",
    "test_new_transx['category_3'] = test_new_transx['category_3'].map({'A': 0, 'B': 1, 'C': 2})\n",
    "test_new_transx['months_since_purchase'] = (((datetime.datetime.today() - test_new_transx['exec_date']).dt.days) / 30) + test_new_transx['month_lag']\n",
    "test_new_transx['duration'] = test_new_transx['purchase_amount'] * test_new_transx['months_since_purchase']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate historical / new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transx_staging = new_transx[\n",
    "    [\n",
    "        'card_id', \n",
    "        'exec_date',\n",
    "        'city_id', \n",
    "        'installments',\n",
    "        'merchant_category_id', \n",
    "        'month_lag',\n",
    "        'purchase_amount', \n",
    "        'category_2', \n",
    "        'state_id',\n",
    "        'subsector_id', \n",
    "        'nan_merchant_id', \n",
    "        'nan_category_3', \n",
    "        'nan_category_2',\n",
    "        'authorized_flag',\n",
    "        'category_1',\n",
    "        'category_3', \n",
    "        'month', \n",
    "        'year', \n",
    "        'day', \n",
    "        'weekday', \n",
    "        'week_of_year',\n",
    "        'day_of_year',\n",
    "        'day_of_week',\n",
    "        'days_since_purchase',\n",
    "        'is_month_start',\n",
    "        'is_month_end',\n",
    "        'is_weekend',\n",
    "        'is_weekday',\n",
    "        'quarter',\n",
    "        'hour',\n",
    "        'months_since_purchase',\n",
    "        'duration'\n",
    "    ]\n",
    "].reset_index(drop = True)\n",
    "\n",
    "del new_transx\n",
    "gc.collect()\n",
    "\n",
    "new_transx_staging = new_transx_staging.groupby('card_id').agg(agg_inputs).reset_index()\n",
    "new_transx_staging.columns = ['new_' + '_'.join(col).strip() for col in new_transx_staging.columns.values]\n",
    "new_transx_staging = new_transx_staging.rename(columns={new_transx_staging.columns[0] : 'card_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new_transx_staging = test_new_transx[\n",
    "    [\n",
    "        'card_id', \n",
    "        'exec_date',\n",
    "        'city_id', \n",
    "        'installments',\n",
    "        'merchant_category_id', \n",
    "        'month_lag',\n",
    "        'purchase_amount', \n",
    "        'category_2', \n",
    "        'state_id',\n",
    "        'subsector_id', \n",
    "        'nan_merchant_id', \n",
    "        'nan_category_3', \n",
    "        'nan_category_2',\n",
    "        'authorized_flag',\n",
    "        'category_1',\n",
    "        'category_3', \n",
    "        'month', \n",
    "        'year', \n",
    "        'day', \n",
    "        'weekday', \n",
    "        'week_of_year',\n",
    "        'day_of_year',\n",
    "        'day_of_week',\n",
    "        'days_since_purchase',\n",
    "        'is_month_start',\n",
    "        'is_month_end',\n",
    "        'is_weekend',\n",
    "        'is_weekday',\n",
    "        'quarter',\n",
    "        'hour',\n",
    "        'months_since_purchase',\n",
    "        'duration'\n",
    "    ]\n",
    "].reset_index(drop = True)\n",
    "\n",
    "del test_new_transx\n",
    "gc.collect()\n",
    "\n",
    "test_new_transx_staging = test_new_transx_staging \\\n",
    "    .groupby('card_id') \\\n",
    "    .agg(agg_inputs) \\\n",
    "    .reset_index()\n",
    "\n",
    "test_new_transx_staging.columns = [\n",
    "    'new_' + '_'.join(col).strip() \n",
    "        for col in test_new_transx_staging.columns.values\n",
    "]\n",
    "\n",
    "test_new_transx_staging = test_new_transx_staging.rename(columns={test_new_transx_staging.columns[0] : 'card_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.merge(train, new_transx_staging, on = 'card_id', how = 'left')\n",
    "\n",
    "test = pd.merge(test, test_new_transx_staging, on = 'card_id', how = 'left')\n",
    "\n",
    "del [test_new_transx_staging, new_transx_staging]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain features\n",
    "* DONE Sum historical and new purchase amounts\n",
    "* DONE Average day of purchase\n",
    "* DONE Min / Max day of year\n",
    "* DONE How dense are purchases?\n",
    "* DONE Time of day\n",
    "* DONE How consistent are they with amounts? Standard dev of amounts\n",
    "* Store level score averages\n",
    "* DONE Pct authorized flag = N\n",
    "* DONE First month / year -> get more granular\n",
    "* Month lag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "train['new_hist_purch_amt_max'] = train['h_t_purchase_amount_max'] + train['new_purchase_amount_max']\n",
    "test['new_hist_purch_amt_max'] = test['h_t_purchase_amount_max'] + test['new_purchase_amount_max']\n",
    "\n",
    "train['new_time_elapsed'] = (train['new_exec_date_max'] - train['new_exec_date_min']).dt.days\n",
    "test['new_time_elapsed'] = (test['new_exec_date_max'] - test['new_exec_date_min']).dt.days\n",
    "train['h_t_time_elapsed'] = (train['h_t_exec_date_max'] - train['h_t_exec_date_min']).dt.days\n",
    "test['h_t_time_elapsed'] = (test['h_t_exec_date_max'] - test['h_t_exec_date_min']).dt.days\n",
    "\n",
    "train['days_since_first_purch'] = (datetime.datetime.today() - train['first_purch']).dt.days\n",
    "test['days_since_first_purch'] = (datetime.datetime.today() - test['first_purch']).dt.days\n",
    "\n",
    "train['new_days_since_first_exec'] = (datetime.datetime.today() - train['new_exec_date_min']).dt.days\n",
    "test['new_days_since_first_exec'] = (datetime.datetime.today() - test['new_exec_date_min']).dt.days\n",
    "train['h_t_days_since_first_exec'] = (datetime.datetime.today() - train['h_t_exec_date_min']).dt.days\n",
    "test['h_t_days_since_first_exec'] = (datetime.datetime.today() - test['h_t_exec_date_min']).dt.days\n",
    "\n",
    "\n",
    "train['new_days_since_last_exec'] = (datetime.datetime.today() - train['new_exec_date_max']).dt.days\n",
    "test['new_days_since_last_exec'] = (datetime.datetime.today() - test['new_exec_date_max']).dt.days\n",
    "train['h_t_days_since_last_exec'] = (datetime.datetime.today() - train['h_t_exec_date_max']).dt.days\n",
    "test['h_t_days_since_last_exec'] = (datetime.datetime.today() - test['h_t_exec_date_max']).dt.days\n",
    "\n",
    "train['h_t_avg_purch_per_day'] = train['h_t_time_elapsed'] / train['h_t_card_id_size']\n",
    "test['h_t_avg_purch_per_day'] = test['h_t_time_elapsed'] / test['h_t_card_id_size']\n",
    "train['new_avg_purch_per_day'] = train['new_time_elapsed'] / train['new_card_id_size']\n",
    "test['new_avg_purch_per_day'] = test['new_time_elapsed'] / test['new_card_id_size']\n",
    "\n",
    "train['h_t_days_between_first_purchases'] = (train['h_t_exec_date_min'] - train['first_purch']).dt.days\n",
    "test['h_t_days_between_first_purchases'] = (test['h_t_exec_date_min'] - test['first_purch']).dt.days\n",
    "train['new_days_between_first_purchases'] = (train['new_exec_date_min'] - train['first_purch']).dt.days\n",
    "test['new_days_between_first_purchases'] = (test['new_exec_date_min'] - test['first_purch']).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run predictions, submit csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1114]\ttraining's rmse: 3.21751\tvalid_1's rmse: 3.64918\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[728]\ttraining's rmse: 3.31351\tvalid_1's rmse: 3.6078\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[668]\ttraining's rmse: 3.29731\tvalid_1's rmse: 3.7564\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[754]\ttraining's rmse: 3.29668\tvalid_1's rmse: 3.63212\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[658]\ttraining's rmse: 3.33376\tvalid_1's rmse: 3.64113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.65768791336576"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, RepeatedKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt\n",
    "\n",
    "x = train.copy().drop([\n",
    "    'first_active_month',\n",
    "    'first_purch',\n",
    "    'card_id',\n",
    "    'new_exec_date_min',\n",
    "    'new_exec_date_max',\n",
    "    'h_t_exec_date_min',\n",
    "    'h_t_exec_date_max'\n",
    "], axis = 1)\n",
    "\n",
    "y = train['target']\n",
    "\n",
    "x_submit = test.copy().drop([\n",
    "    'first_active_month',\n",
    "    'first_purch',\n",
    "    'card_id',\n",
    "    'new_exec_date_min',\n",
    "    'new_exec_date_max',\n",
    "    'h_t_exec_date_min',\n",
    "    'h_t_exec_date_max'\n",
    "], axis = 1)\n",
    "\n",
    "param = {'num_leaves': 31,\n",
    "        'min_data_in_leaf': 27,\n",
    "        'objective': 'regression',\n",
    "        'max_depth': -1,\n",
    "        'learning_rate': 0.015,\n",
    "        'boosting': 'gbdt',\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_seed': 11,\n",
    "        'metric': 'rmse',\n",
    "        'lambda_l1': 0.1,\n",
    "        'verbosity': -1,\n",
    "        'nthread': 4,\n",
    "        'random_state': 4950}\n",
    "\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "train_predictions = np.zeros(len(train))\n",
    "test_predictions = np.zeros(len(test))\n",
    "\n",
    "for train_index, val_index in folds.split(x, x['feature_1']):\n",
    "    y = x['target']\n",
    "    x0 = x.drop('target', axis = 1)\n",
    "    \n",
    "    trn_data = lgb.Dataset(x0.iloc[train_index], label=y.iloc[train_index])\n",
    "    val_data = lgb.Dataset(x0.iloc[val_index], label=y.iloc[val_index])\n",
    "    \n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data],\n",
    "                   verbose_eval = -1, early_stopping_rounds = 200)\n",
    "    train_predictions[val_index] = clf.predict(x0.iloc[val_index], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    test_predictions += clf.predict(x_submit, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "np.sqrt(mean_squared_error(train_predictions, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(\n",
    "                data = {\n",
    "                    'card_id' : test['card_id'],\n",
    "                    'target' : test_predictions\n",
    "                }).to_csv('submit.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
