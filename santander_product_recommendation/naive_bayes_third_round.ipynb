{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Third Round\n",
    "26/11/2016  \n",
    "ironbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to use the new splitted dataset to train a naive bayes model. I will be using a class for the dataset, and this will help me for later using a unified class for the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import time\n",
    "import gzip\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from dataset import SantanderDataset\n",
    "from average_precision import mapk\n",
    "from genetic_search import genetic_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 3 seconds to load the dataset\n",
      "It took 4 seconds to load the dataset\n",
      "It took 6 seconds to load the dataset\n",
      "It took 2 seconds to load the dataset\n",
      "1375686 1375686\n",
      "561234 561234\n"
     ]
    }
   ],
   "source": [
    "dataset_root = '/mnt/F25663CB56638EE3/Kaggle/Santander Product Recommendation/'\n",
    "dataset = SantanderDataset(dataset_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have been testing the class and seems to be working fine. \n",
    "When loaded the dataset is using only 500MB of RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bnb_model(msg):\n",
    "    \"\"\"\n",
    "    Trains a model using the given parameters\n",
    "    \n",
    "    month: int or list with the number of the month we want\n",
    "        the data to be taken of\n",
    "    input_columns: a list with the name of the columns we are going to use\n",
    "        in the task\n",
    "    use_product: bool, if true adds the product columns of the month before\n",
    "    use_change: bool, if true adds the change columns of the month before\n",
    "    \"\"\"\n",
    "    msg_copy = msg.copy()\n",
    "    msg_copy['train'] = True\n",
    "    if not 'month' in msg_copy.keys():\n",
    "        msg_copy['month'] = msg_copy['train_month']\n",
    "    #Get the data for training\n",
    "    ret = dataset.get_data(msg_copy)\n",
    "    input_data, output_data = ret[0:2]\n",
    "    #Fit the model\n",
    "    bnb = BernoulliNB(alpha=1e-2)\n",
    "    bnb.partial_fit(input_data, output_data, classes = range(24))\n",
    "    return bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_prediction(bnb, msg):\n",
    "    \"\"\"\n",
    "    Makes a prediction using the given model and parameters\n",
    "    \n",
    "    month: int or list with the number of the month we want\n",
    "        the data to be taken of\n",
    "    input_columns: a list with the name of the columns we are going to use\n",
    "        in the task\n",
    "    use_product: bool, if true adds the product columns of the month before\n",
    "    use_change: bool, if true adds the change columns of the month before\n",
    "    \"\"\"\n",
    "    msg_copy = msg.copy()\n",
    "    msg_copy['train'] = False\n",
    "    if not 'month' in msg_copy.keys():\n",
    "        msg_copy['month'] = msg_copy['eval_month']\n",
    "    #Get the data for making a prediction\n",
    "    ret = dataset.get_data(msg_copy)\n",
    "    input_data, output_data, previous_products = ret\n",
    "    #Get the prediction\n",
    "    rank = bnb.predict_proba(input_data)\n",
    "    filtered_rank = np.equal(previous_products, 0) * rank\n",
    "    predictions = np.argsort(filtered_rank, axis=1)\n",
    "    predictions = predictions[:,::-1][:,0:7]\n",
    "    return predictions, output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_bayes_workflow(msg):\n",
    "    \"\"\"\n",
    "    Implements all the steps of training and evaluating a naive bayes classifier\n",
    "    Returns the score and the trained model\n",
    "    \n",
    "    train_month: int or list with the number of the month we want\n",
    "        the data to be taken of for training \n",
    "    eval_month: int or list with the number of the month we want\n",
    "        the data to be taken of for testing\n",
    "    input_columns: a list with the name of the columns we are going to use\n",
    "        in the task\n",
    "    use_product: bool, if true adds the product columns of the month before\n",
    "    use_change: bool, if true adds the change columns of the month before\n",
    "    \"\"\"\n",
    "    if type(msg['eval_month']) is not list:\n",
    "        msg['eval_month'] = [msg['eval_month']]\n",
    "    #Train the model\n",
    "    bnb = train_bnb_model(msg)\n",
    "    scores = []\n",
    "    for month in msg['eval_month']:\n",
    "        msg_copy = msg.copy()\n",
    "        msg_copy['month'] = month\n",
    "        #Create prediction\n",
    "        predictions, output_data = create_prediction(bnb, msg_copy)\n",
    "        #Get the score\n",
    "        score = mapk(output_data, predictions)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return scores, bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70998466756819612]\n",
      "0.263981103897\n"
     ]
    }
   ],
   "source": [
    "#Try training\n",
    "start_time = time.time()\n",
    "msg = {'train_month': 5,\n",
    "       'eval_month': 5,\n",
    "      'input_columns': [],\n",
    "      'use_product': True,\n",
    "      'use_change': False}\n",
    "print naive_bayes_workflow(msg)[0]\n",
    "print time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70271425855404612]\n",
      "1.11327409744\n"
     ]
    }
   ],
   "source": [
    "#Try training\n",
    "start_time = time.time()\n",
    "msg = {'train_month': 5,\n",
    "       'eval_month': 5,\n",
    "      'input_columns': dataset.categorical_columns,\n",
    "      'use_product': True,\n",
    "      'use_change': False}\n",
    "print naive_bayes_workflow(msg)[0]\n",
    "print time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6443314161539575]\n",
      "13.2391889095\n"
     ]
    }
   ],
   "source": [
    "#Try training\n",
    "start_time = time.time()\n",
    "msg = {'train_month': range(1,17),\n",
    "       'eval_month': 5,\n",
    "      'input_columns': dataset.categorical_columns,\n",
    "      'use_product': True,\n",
    "      'use_change': False}\n",
    "print naive_bayes_workflow(msg)[0]\n",
    "print time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70998466756819612, 0.69814177663890675]\n",
      "0.414514064789\n"
     ]
    }
   ],
   "source": [
    "#Try training\n",
    "start_time = time.time()\n",
    "msg = {'train_month': 5,\n",
    "       'eval_month': [5,16],\n",
    "      'input_columns': [],\n",
    "      'use_product': True,\n",
    "      'use_change': False}\n",
    "print naive_bayes_workflow(msg)[0]\n",
    "print time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40694810750308774, 0.47310000284717768]\n",
      "3.57399702072\n"
     ]
    }
   ],
   "source": [
    "#Try training\n",
    "start_time = time.time()\n",
    "msg = {'train_month': [ 1,  2,  3,  6,  9, 12, 14, 15],\n",
    "       'eval_month': [5,16],\n",
    "      'input_columns': ['pais_residencia', 'age', 'antiguedad', 'tiprel_1mes',\n",
    "                        'indresi', 'indext', 'canal_entrada', 'nomprov', 'renta',\n",
    "                        'segmento', 'month'],\n",
    "      'use_product': True,\n",
    "      'use_change': False}\n",
    "print naive_bayes_workflow(msg)[0]\n",
    "print time.time()-start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very good, it seems to be working correctly and it's much faster than the other implementations, in the worst case I will be running 4 experiments per minute. And in the best case it will run 240 experiments per minute.\n",
    "\n",
    "In the previos implementation the average time was 2 experiments per minute.\n",
    "So we get an speedup of 2 to 120."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic algorithm search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to launch a new search to see if I can get the same results or better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_genomic_score(test_month, filename, genome, verbose=False):\n",
    "    \"\"\"\n",
    "    Receives only test month and the genome\n",
    "    Returns the score and saves the configuration and results in a file\n",
    "    \n",
    "    If the genome size is 34 then use_product is set to True\n",
    "    If the genome size is 35 then all the parameters are in the search\n",
    "    len(categorical_columns) = 18\n",
    "    So we need a genome of 18+2+1 = 21\n",
    "    \"\"\"\n",
    "    if verbose: print genome\n",
    "    #Decide which train months to use, we can train from month 1 to 16\n",
    "    if np.sum(genome[0:15]) > 0:\n",
    "        used_months = np.array(range(1,5)+range(6,17))[np.array(genome[0:15]) == 1]\n",
    "        train_month = used_months\n",
    "    else:\n",
    "        #Select a random month, excluding 5\n",
    "        used_months = np.random.randint(1,16,1)[0]\n",
    "        if used_months >= 5: used_months += 1\n",
    "        train_month = [used_months]\n",
    "    if verbose: print 'train_month', train_month\n",
    "    #Decide wich category input columns to use\n",
    "    categorical_columns = dataset.categorical_columns\n",
    "    used_index = np.arange(len(categorical_columns))[\n",
    "        np.array(genome[15:33]) == 1]\n",
    "    input_columns = [categorical_columns[i] for i in used_index]\n",
    "    if verbose: print 'input_columns', input_columns\n",
    "    #Decide on using change columns and product as input\n",
    "    use_change = genome[33] == 1\n",
    "    #This allows to use a shorter genome to fix some properties\n",
    "    if len(genome) >= 35: \n",
    "        use_product = genome[34] == 1\n",
    "    else:\n",
    "        use_product = True\n",
    "    #Build message for training \n",
    "    msg ={'train_month':list(train_month),\n",
    "          'eval_month':test_month,\n",
    "          'input_columns':input_columns,\n",
    "          'use_product':use_product,\n",
    "          'use_change':use_change,\n",
    "        \n",
    "    }\n",
    "    if verbose: print msg\n",
    "    ret = naive_bayes_workflow(msg)\n",
    "    #Print and save to file \n",
    "    text = '\\t'.join([str(a) for a in ret[0]]) + '\\t'\n",
    "    text += '%s\\t%s\\t' % ( use_change, use_product)\n",
    "    if verbose: print text\n",
    "    text += \"','\".join(input_columns)\n",
    "    text += \"\\t\" + \",\".join([str(a) for a in train_month])\n",
    "    text += '\\n'\n",
    "    with open(dataset_root+'logs/%s.log' % filename, 'a') as f:\n",
    "        f.write(text)\n",
    "        \n",
    "    return ret[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define evaluation function\n",
    "def eval_function_1(individual):\n",
    "    \"\"\"\n",
    "    Tries to optimize just the training score\n",
    "    \"\"\"\n",
    "    ret = get_genomic_score([5,16],'genetic_search_6',individual,verbose=False)\n",
    "    return ret[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting genetic search\n",
      "gen\tnevals\tavg     \tmin     \tmax     \n",
      "0  \t20    \t0.545802\t0.209659\t0.724581\n",
      "1  \t15    \t0.669912\t0.474358\t0.74746 \n",
      "2  \t15    \t0.700577\t0.390444\t0.736404\n",
      "3  \t14    \t0.719218\t0.589063\t0.74221 \n",
      "4  \t7     \t0.733946\t0.720324\t0.762314\n",
      "5  \t14    \t0.746143\t0.722385\t0.762739\n",
      "6  \t12    \t0.755809\t0.709811\t0.768207\n",
      "7  \t11    \t0.743561\t0.582151\t0.768207\n",
      "8  \t12    \t0.756928\t0.653292\t0.768207\n",
      "9  \t13    \t0.76731 \t0.762362\t0.768207\n",
      "10 \t16    \t0.745436\t0.615905\t0.774615\n",
      "Best individual is: [0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1]\n",
      "with fitness: (0.77461455927031386,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1]],\n",
       " [{'avg': 0.54580184103540563,\n",
       "   'gen': 0,\n",
       "   'max': 0.72458057561601341,\n",
       "   'min': 0.20965925692443163,\n",
       "   'nevals': 20},\n",
       "  {'avg': 0.6699119392363494,\n",
       "   'gen': 1,\n",
       "   'max': 0.7474601173322355,\n",
       "   'min': 0.47435753882484794,\n",
       "   'nevals': 15},\n",
       "  {'avg': 0.7005767488216269,\n",
       "   'gen': 2,\n",
       "   'max': 0.73640422846812437,\n",
       "   'min': 0.39044386859971336,\n",
       "   'nevals': 15},\n",
       "  {'avg': 0.71921807647370506,\n",
       "   'gen': 3,\n",
       "   'max': 0.74221045159378185,\n",
       "   'min': 0.58906335769177987,\n",
       "   'nevals': 14},\n",
       "  {'avg': 0.73394556313659787,\n",
       "   'gen': 4,\n",
       "   'max': 0.762314380012732,\n",
       "   'min': 0.72032378936805275,\n",
       "   'nevals': 7},\n",
       "  {'avg': 0.74614269102463671,\n",
       "   'gen': 5,\n",
       "   'max': 0.76273851455407649,\n",
       "   'min': 0.72238525156099909,\n",
       "   'nevals': 14},\n",
       "  {'avg': 0.75580873139761828,\n",
       "   'gen': 6,\n",
       "   'max': 0.76820694887585195,\n",
       "   'min': 0.70981126135012129,\n",
       "   'nevals': 12},\n",
       "  {'avg': 0.74356065250808145,\n",
       "   'gen': 7,\n",
       "   'max': 0.76820694887585195,\n",
       "   'min': 0.58215121249027946,\n",
       "   'nevals': 11},\n",
       "  {'avg': 0.75692811857922404,\n",
       "   'gen': 8,\n",
       "   'max': 0.76820694887585195,\n",
       "   'min': 0.65329221892487377,\n",
       "   'nevals': 12},\n",
       "  {'avg': 0.76730961178249324,\n",
       "   'gen': 9,\n",
       "   'max': 0.76820694887585195,\n",
       "   'min': 0.76236237501524784,\n",
       "   'nevals': 13},\n",
       "  {'avg': 0.745436156402002,\n",
       "   'gen': 10,\n",
       "   'max': 0.77461455927031386,\n",
       "   'min': 0.61590456106193681,\n",
       "   'nevals': 16}],\n",
       " <deap.tools.support.HallOfFame at 0x7fcd2d117c90>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'Starting genetic search'\n",
    "genetic_search(eval_function_1, 35, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.774615 is 0.04 points better than my previous best score, so I have to make a submission of this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing for month 5 and 16\n",
    "That search took only a few minutes. So I'm thinking of launching a search with population 10x size_vector which was the recommended parameter.  \n",
    "Moreover I think that a good combination will be to maximize the sum of month 5 and 16, because we have discovered that both are important. If doing so I can't use the month 16 for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_genomic_score(test_month, filename, genome, verbose=False):\n",
    "    \"\"\"\n",
    "    Receives only test month and the genome\n",
    "    Returns the score and saves the configuration and results in a file\n",
    "    It's the same function as above but without training with month 16\n",
    "    \n",
    "    If the genome size is 33 then use_product is set to True\n",
    "    If the genome size is 34 then all the parameters are in the search\n",
    "    len(categorical_columns) = 18\n",
    "    So we need a genome of 18+2+1 = 21\n",
    "    \"\"\"\n",
    "    if verbose: print genome\n",
    "    #Decide which train months to use, we can train from month 1 to 15\n",
    "    if np.sum(genome[0:14]) > 0:\n",
    "        used_months = np.array(range(1,5)+range(6,16))[np.array(genome[0:14]) == 1]\n",
    "        train_month = used_months\n",
    "    else:\n",
    "        #Select a random month, excluding 5 and 16\n",
    "        used_months = np.random.randint(1,15,1)[0]\n",
    "        if used_months >= 5: used_months += 1\n",
    "        train_month = [used_months]\n",
    "    if verbose: print 'train_month', train_month\n",
    "    #Decide wich category input columns to use\n",
    "    categorical_columns = dataset.categorical_columns\n",
    "    used_index = np.arange(len(categorical_columns))[\n",
    "        np.array(genome[14:32]) == 1]\n",
    "    input_columns = [categorical_columns[i] for i in used_index]\n",
    "    if verbose: print 'input_columns', input_columns\n",
    "    #Decide on using change columns and product as input\n",
    "    use_change = genome[32] == 1\n",
    "    #This allows to use a shorter genome to fix some properties\n",
    "    if len(genome) >= 34: \n",
    "        use_product = genome[33] == 1\n",
    "    else:\n",
    "        use_product = True\n",
    "    #Build message for training \n",
    "    msg ={'train_month':list(train_month),\n",
    "          'eval_month':test_month,\n",
    "          'input_columns':input_columns,\n",
    "          'use_product':use_product,\n",
    "          'use_change':use_change,\n",
    "        \n",
    "    }\n",
    "    if verbose: print msg\n",
    "    ret = naive_bayes_workflow(msg)\n",
    "    #Print and save to file \n",
    "    text = '\\t'.join([str(a) for a in ret[0]]) + '\\t'\n",
    "    text += '%s\\t%s\\t' % ( use_change, use_product)\n",
    "    if verbose: print text\n",
    "    text += \"','\".join(input_columns)\n",
    "    text += \"\\t\" + \",\".join([str(a) for a in train_month])\n",
    "    text += '\\n'\n",
    "    with open(dataset_root+'logs/%s.log' % filename, 'a') as f:\n",
    "        f.write(text)\n",
    "        \n",
    "    return ret[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define evaluation function\n",
    "def eval_function_2(individual):\n",
    "    \"\"\"\n",
    "    Tries to optimize just the training score\n",
    "    \"\"\"\n",
    "    ret = get_genomic_score([5,16],'genetic_search_8',individual,verbose=False)\n",
    "    return [np.sum(ret)/2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting genetic search\n",
      "gen\tnevals\tavg     \tmin     \tmax   \n",
      "0  \t340   \t0.592641\t0.188547\t0.7812\n",
      "1  \t191   \t0.695659\t0.215814\t0.78298\n",
      "2  \t235   \t0.736885\t0.458637\t0.785192\n",
      "3  \t195   \t0.757393\t0.467118\t0.788487\n",
      "4  \t207   \t0.766627\t0.477035\t0.788897\n",
      "5  \t205   \t0.771692\t0.496372\t0.790543\n",
      "6  \t196   \t0.777418\t0.582846\t0.792135\n",
      "7  \t187   \t0.779412\t0.432271\t0.794846\n",
      "8  \t199   \t0.780342\t0.468057\t0.795329\n",
      "9  \t198   \t0.780714\t0.58507 \t0.795329\n",
      "10 \t224   \t0.783707\t0.595911\t0.795329\n",
      "Best individual is: [0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1]\n",
      "with fitness: (0.79532941149303316,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'Starting genetic search'\n",
    "genetic_search(eval_function_2, 34, 340)\n",
    "print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing and training only with month 5\n",
    "I want to know what the maximun score I can get using only month 5 as input. I don't think this will get a good score at the LB, but it will give me a measure of the overfitting capacity of Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_genomic_score(test_month, filename, genome, verbose=False):\n",
    "    \"\"\"\n",
    "    Receives only test month and the genome\n",
    "    Returns the score and saves the configuration and results in a file\n",
    "    In this version only trains with month 5\n",
    "    \n",
    "    If the genome size is 33 then use_product is set to True\n",
    "    If the genome size is 34 then all the parameters are in the search\n",
    "    len(categorical_columns) = 18\n",
    "    So we need a genome of 18+2+1 = 21\n",
    "    \"\"\"\n",
    "    if verbose: print genome\n",
    "    train_month = [5]\n",
    "    if verbose: print 'train_month', train_month\n",
    "    #Decide wich category input columns to use\n",
    "    categorical_columns = dataset.categorical_columns\n",
    "    used_index = np.arange(len(categorical_columns))[\n",
    "        np.array(genome[0:18]) == 1]\n",
    "    input_columns = [categorical_columns[i] for i in used_index]\n",
    "    if verbose: print 'input_columns', input_columns\n",
    "    #Decide on using change columns and product as input\n",
    "    use_change = genome[18] == 1\n",
    "    #This allows to use a shorter genome to fix some properties\n",
    "    if len(genome) >= 20: \n",
    "        use_product = genome[19] == 1\n",
    "    else:\n",
    "        use_product = True\n",
    "    #Build message for training \n",
    "    msg ={'train_month':list(train_month),\n",
    "          'eval_month':test_month,\n",
    "          'input_columns':input_columns,\n",
    "          'use_product':use_product,\n",
    "          'use_change':use_change,\n",
    "        \n",
    "    }\n",
    "    if verbose: print msg\n",
    "    ret = naive_bayes_workflow(msg)\n",
    "    #Print and save to file \n",
    "    text = '\\t'.join([str(a) for a in ret[0]]) + '\\t'\n",
    "    text += '%s\\t%s\\t' % ( use_change, use_product)\n",
    "    if verbose: print text\n",
    "    text += \"','\".join(input_columns)\n",
    "    text += \"\\t\" + \",\".join([str(a) for a in train_month])\n",
    "    text += '\\n'\n",
    "    with open(dataset_root+'logs/%s.log' % filename, 'a') as f:\n",
    "        f.write(text)\n",
    "        \n",
    "    return ret[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define evaluation function\n",
    "def eval_function_3(individual):\n",
    "    \"\"\"\n",
    "    Tries to optimize just the training score\n",
    "    \"\"\"\n",
    "    ret = get_genomic_score([5,16],'genetic_search_9',individual,verbose=False)\n",
    "    return ret[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting genetic search\n",
      "gen\tnevals\tavg     \tmin     \tmax     \n",
      "0  \t200   \t0.722195\t0.604088\t0.810613\n",
      "1  \t135   \t0.767344\t0.608128\t0.810376\n",
      "2  \t112   \t0.796849\t0.627525\t0.810419\n",
      "3  \t114   \t0.802581\t0.705432\t0.810376\n",
      "4  \t109   \t0.80584 \t0.711465\t0.810585\n",
      "5  \t103   \t0.806342\t0.710263\t0.810609\n",
      "6  \t117   \t0.804791\t0.636801\t0.810627\n",
      "7  \t110   \t0.807389\t0.706559\t0.810743\n",
      "8  \t122   \t0.806079\t0.624544\t0.810764\n",
      "9  \t108   \t0.807707\t0.715384\t0.810973\n",
      "10 \t125   \t0.809105\t0.719293\t0.811014\n",
      "Best individual is: [0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1]\n",
      "with fitness: (0.81101371663578969,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'Starting genetic search'\n",
    "genetic_search(eval_function_3, 20, 200)\n",
    "print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing with all the months\n",
    "The idea is to leave the option of using all the months for training. And optimize the sum of the month 5 and 16.  \n",
    "I have seen that optimizing wiht month 5 only for month 5 was not a good idea. But I think optimizing for both months at the same time will get a greater score even if I use those months for also for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_genomic_score(test_month, filename, genome, verbose=False):\n",
    "    \"\"\"\n",
    "    Receives only test month and the genome\n",
    "    Returns the score and saves the configuration and results in a file\n",
    "    It's the same function as above but without training with month 16\n",
    "    \n",
    "    If the genome size is 35 then use_product is set to True\n",
    "    If the genome size is 36 then all the parameters are in the search\n",
    "    len(categorical_columns) = 18\n",
    "    So we need a genome of 18+2+1 = 21\n",
    "    \"\"\"\n",
    "    if verbose: print genome\n",
    "    #Decide which train months to use, from 1 to 16\n",
    "    if np.sum(genome[0:16]) > 0:\n",
    "        used_months = np.array(range(1,17))[np.array(genome[0:16]) == 1]\n",
    "        train_month = used_months\n",
    "    else:\n",
    "        #Select a random month\n",
    "        used_months = np.random.randint(1,17,1)[0]\n",
    "        train_month = [used_months]\n",
    "    if verbose: print 'train_month', train_month\n",
    "    #Decide wich category input columns to use\n",
    "    categorical_columns = dataset.categorical_columns\n",
    "    used_index = np.arange(len(categorical_columns))[\n",
    "        np.array(genome[16:34]) == 1]\n",
    "    input_columns = [categorical_columns[i] for i in used_index]\n",
    "    if verbose: print 'input_columns', input_columns\n",
    "    #Decide on using change columns and product as input\n",
    "    use_change = genome[34] == 1\n",
    "    #This allows to use a shorter genome to fix some properties\n",
    "    if len(genome) >= 36: \n",
    "        use_product = genome[35] == 1\n",
    "    else:\n",
    "        use_product = True\n",
    "    #Build message for training \n",
    "    msg ={'train_month':list(train_month),\n",
    "          'eval_month':test_month,\n",
    "          'input_columns':input_columns,\n",
    "          'use_product':use_product,\n",
    "          'use_change':use_change,\n",
    "        \n",
    "    }\n",
    "    if verbose: print msg\n",
    "    ret = naive_bayes_workflow(msg)\n",
    "    #Print and save to file \n",
    "    text = '\\t'.join([str(a) for a in ret[0]]) + '\\t'\n",
    "    text += '%s\\t%s\\t' % ( use_change, use_product)\n",
    "    if verbose: print text\n",
    "    text += \"','\".join(input_columns)\n",
    "    text += \"\\t\" + \",\".join([str(a) for a in train_month])\n",
    "    text += '\\n'\n",
    "    with open(dataset_root+'logs/%s.log' % filename, 'a') as f:\n",
    "        f.write(text)\n",
    "        \n",
    "    return ret[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define evaluation function\n",
    "def eval_function_4(individual):\n",
    "    \"\"\"\n",
    "    Tries to optimize just the training score\n",
    "    \"\"\"\n",
    "    ret = get_genomic_score([5,16],'genetic_search_10',individual,verbose=False)\n",
    "    return [np.sum(ret)/2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting genetic search\n",
      "gen\tnevals\tavg     \tmin     \tmax     \n",
      "0  \t600   \t0.618919\t0.124393\t0.801854\n",
      "1  \t372   \t0.718242\t0.38189 \t0.803338\n",
      "2  \t366   \t0.760257\t0.39911 \t0.801854\n",
      "3  \t345   \t0.778502\t0.433457\t0.807679\n",
      "4  \t377   \t0.787126\t0.562399\t0.807949\n",
      "5  \t345   \t0.78831 \t0.18722 \t0.809957\n",
      "6  \t348   \t0.789446\t0.42857 \t0.811588\n",
      "7  \t353   \t0.794426\t0.423332\t0.815588\n",
      "8  \t353   \t0.798246\t0.184611\t0.815588\n",
      "9  \t361   \t0.798675\t0.525028\t0.815588\n",
      "10 \t382   \t0.801234\t0.149588\t0.815665\n",
      "Best individual is: [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "with fitness: (0.81566519477227328,)\n",
      "21031.625947\n"
     ]
    }
   ],
   "source": [
    "print 'Starting genetic search'\n",
    "start_time = time.time()\n",
    "genetic_search(eval_function_4, 36, 600)\n",
    "print time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.797194779659\t0.794576261656\tTrue\tTrue\tage\t3,4,5,7,14,15\n",
    "0.805916016012\t0.818480415688\t1.6243964317\tTrue\tTrue\tpais_residencia','age','indrel','indrel_1mes','indext','segmento','month\t1,2,5,6,10,11,16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have to create a submission function, I will reuse the one from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_submission(filename, msg, \n",
    "                        verbose=False):\n",
    "    \"\"\"\n",
    "    Implements all the steps of training and evaluating a naive bayes classifier\n",
    "    Returns the score and the trained model\n",
    "    \n",
    "    train_month: int or list with the number of the month we want\n",
    "        the data to be taken of for training \n",
    "    eval_month: int or list with the number of the month we want\n",
    "        the data to be taken of for testing\n",
    "    input_columns: a list with the name of the columns we are going to use\n",
    "        in the task\n",
    "    use_product: bool, if true adds the product columns of the month before\n",
    "    use_change: bool, if true adds the change columns of the month before\n",
    "    \"\"\"\n",
    "    test_month = 17\n",
    "    #Train the model and get validation scores\n",
    "    ret = naive_bayes_workflow(msg)\n",
    "    scores = ret[0]\n",
    "    bnb = ret[1]\n",
    "    #Create a prediction\n",
    "    msg['month'] = test_month\n",
    "    predictions, output_data = create_prediction(bnb, msg)\n",
    "    #Create the submission text\n",
    "    if verbose: print 'Creating text...'\n",
    "    text='ncodpers,added_products\\n'\n",
    "    for i, ncodpers in enumerate(dataset.eval_current[dataset.eval_current.fecha_dato == test_month].ncodpers):\n",
    "        text += '%i,' % ncodpers\n",
    "        for j in predictions[i]:\n",
    "            text += '%s ' % dataset.product_columns[j]\n",
    "        text += '\\n'\n",
    "    #Write to file\n",
    "    if verbose: print 'Writing to file...'\n",
    "    with gzip.open(dataset_root + 'submissions/%s.csv.gz' % filename, 'w') as f:\n",
    "        f.write(text)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77461455927031386, 0.79387365791159514]\n",
      "38.1280529499\n"
     ]
    }
   ],
   "source": [
    "#Create submission\n",
    "start_time = time.time()\n",
    "msg = {'train_month': [ 6,8,11,12,14,15],\n",
    "       'eval_month': [5,16],\n",
    "      'input_columns': ['ind_empleado','pais_residencia','age','indrel',\n",
    "                        'indresi','indext','canal_entrada','renta'],\n",
    "      'use_product': True,\n",
    "      'use_change': True}\n",
    "print create_submission('NaiveBayes_8',msg)\n",
    "print time.time()-start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I get a LB score of 0.0256351"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78770011140463214, 0.79456803473556825]\n",
      "33.0553078651\n"
     ]
    }
   ],
   "source": [
    "#Create submission\n",
    "start_time = time.time()\n",
    "msg = {'train_month': [ 3,4,11,15],\n",
    "       'eval_month': [5,16],\n",
    "      'input_columns': ['ind_empleado','pais_residencia','sexo',\n",
    "                        'indrel_1mes','indfall','renta','segmento'],\n",
    "      'use_product': True,\n",
    "      'use_change': True}\n",
    "print create_submission('NaiveBayes_9',msg)\n",
    "print time.time()-start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I get a LB score of 0.0264266"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81097285715238709, 0.71654820129546593]\n",
      "39.8754160404\n"
     ]
    }
   ],
   "source": [
    "#Create submission\n",
    "start_time = time.time()\n",
    "msg = {'train_month': [5],\n",
    "       'eval_month': [5,16],\n",
    "      'input_columns': ['pais_residencia','sexo','age','tiprel_1mes',\n",
    "                        'canal_entrada','indfall','nomprov','renta'],\n",
    "      'use_product': True,\n",
    "      'use_change': True}\n",
    "print create_submission('NaiveBayes_10',msg)\n",
    "print time.time()-start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I get a LB score of 0.0256338.   \n",
    "This is a clear example of overfitting, I’m getting a good score at month 5, but due to only train with that month the LB score is no better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.797194779659\t0.794576261656\tTrue\tTrue\tage\t3,4,5,7,14,15\n",
    "0.805916016012\t0.818480415688\t1.6243964317\tTrue\tTrue\tpais_residencia','age','indrel','indrel_1mes','indext','segmento','month\t1,2,5,6,10,11,16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80591601601215246, 0.81848041568794927]\n",
      "33.9030869007\n"
     ]
    }
   ],
   "source": [
    "#Create submission\n",
    "start_time = time.time()\n",
    "msg = {'train_month': [1,2,5,6,10,11,16],\n",
    "       'eval_month': [5, 16],\n",
    "      'input_columns': ['pais_residencia','age','indrel','indrel_1mes','indext','segmento','month'],\n",
    "      'use_product': True,\n",
    "      'use_change': True}\n",
    "print create_submission('NaiveBayes_11',msg)\n",
    "print time.time()-start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I get a LB score of , 87 in the classification( top 9%)  \n",
    "That's very good for Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
