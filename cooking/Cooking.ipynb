{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Preparation\n",
    "def read_dataset(path):\n",
    "    return json.load(open(path)) \n",
    "train = read_dataset('train.json')\n",
    "test = read_dataset('test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare text data of Train and Test ... \n"
     ]
    }
   ],
   "source": [
    "# Text Data Features\n",
    "print (\"Prepare text data of Train and Test ... \")\n",
    "def generate_text(data):\n",
    "    text_data = [\" \".join(doc['ingredients']).lower() for doc in data]\n",
    "    return text_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = generate_text(train)\n",
    "test_text = generate_text(test)\n",
    "target = [doc['cuisine'] for doc in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF on text data ... \n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering \n",
    "print (\"TF-IDF on text data ... \")\n",
    "tfidf = TfidfVectorizer(binary=True)\n",
    "def tfidf_features(txt, flag):\n",
    "    if flag == \"train\":\n",
    "        x = tfidf.fit_transform(txt)\n",
    "    else:\n",
    "        x = tfidf.transform(txt)\n",
    "    x = x.astype('float16')\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf_features(train_text, flag=\"train\")\n",
    "X_test = tfidf_features(test_text, flag=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encode the Target Variable ... \n"
     ]
    }
   ],
   "source": [
    "# Label Encoding - Target \n",
    "print (\"Label Encode the Target Variable ... \")\n",
    "lb = LabelEncoder()\n",
    "y = lb.fit_transform(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train the model ... \n"
     ]
    }
   ],
   "source": [
    "# Model Training \n",
    "print (\"Train the model ... \")\n",
    "classifier = SVC(C=100, # penalty parameter, setting it to a larger value \n",
    "kernel='rbf', # kernel type, rbf working fine here\n",
    "degree=3, # default value, not tuned yet\n",
    "gamma=1, # kernel coefficient, not tuned yet\n",
    "coef0=1, # change to 1 from default value of 0.0\n",
    "shrinking=True, # using shrinking heuristics\n",
    "tol=0.001, # stopping criterion tolerance \n",
    "probability=False, # no need to enable probability estimates\n",
    "cache_size=200, # 200 MB cache size\n",
    "class_weight=None, # all classes are treated equally \n",
    "verbose=False, # print the logs \n",
    "max_iter=-1, # no limit, let it run\n",
    "decision_function_shape=None, # will use one vs rest explicitly \n",
    "random_state=None)\n",
    "model = OneVsRestClassifier(classifier, n_jobs=4)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions \n",
    "print (\"Predict on test data ... \")\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = lb.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "print (\"Generate Submission File ... \")\n",
    "test_id = [doc['id'] for doc in test]\n",
    "sub = pd.DataFrame({'id': test_id, 'cuisine': y_pred}, columns=['id', 'cuisine'])\n",
    "sub.to_csv('svm.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
