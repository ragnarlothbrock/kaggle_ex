{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning / LGBM for unbalanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "import keras as k\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training df shape (200000, 202)\n",
      "Test df shape (200000, 201)\n",
      "Wall time: 30 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "print('Training df shape', df_train.shape)\n",
    "print('Test df shape', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of transactions made :  10.049\n"
     ]
    }
   ],
   "source": [
    "per = len(df_train[df_train['target']>0]) / df_train.shape[0]\n",
    "print('Percentage of transactions made : ', per*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones :  20098\n",
      "Zeros :  19609\n",
      "(39707, 202)\n"
     ]
    }
   ],
   "source": [
    "df_ones = df_train[df_train['target']>0]\n",
    "print('Ones : ', df_ones.shape[0])\n",
    "df_zeros = df_train[df_train['target']==0].sample(frac=0.109)\n",
    "print('Zeros : ', df_zeros.shape[0])\n",
    "df_sampling = pd.concat([df_ones, df_zeros])\n",
    "print(df_sampling.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating percentiles features for df: 1/3\n",
      "Creating percentiles features for df: 2/3\n",
      "Creating percentiles features for df: 3/3\n",
      "Wall time: 11min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "idx = features = df_train.columns.values[2:202]\n",
    "for i, df in enumerate([df_train, df_test, df_sampling]):\n",
    "    df['sum'] = df[idx].sum(axis=1)\n",
    "    df['min'] = df[idx].sum(axis=1)\n",
    "    df['max'] = df[idx].max(axis=1)\n",
    "    df['mean'] = df[idx].mean(axis=1)\n",
    "    df['std'] = df[idx].std(axis=1)\n",
    "    df['skew'] = df[idx].skew(axis=1)\n",
    "    df['kurt'] = df[idx].kurtosis(axis=1)\n",
    "    df['med'] = df[idx].median(axis=1)\n",
    "    \n",
    "    print('Creating percentiles features for df: {}/{}'.format(i+1,3))\n",
    "    df['perc_5'] =  df[idx].apply(lambda x: np.percentile(x, 10), axis=1)\n",
    "    df['perc_10'] =  df[idx].apply(lambda x: np.percentile(x, 10), axis=1)\n",
    "    df['perc_25'] =  df[idx].apply(lambda x: np.percentile(x, 25), axis=1)\n",
    "    df['perc_50'] =  df[idx].apply(lambda x: np.percentile(x, 50), axis=1)\n",
    "    df['perc_75'] =  df[idx].apply(lambda x: np.percentile(x, 75), axis=1)\n",
    "    df['perc_95'] =  df[idx].apply(lambda x: np.percentile(x, 99), axis=1)\n",
    "    df['perc_99'] =  df[idx].apply(lambda x: np.percentile(x, 99), axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.iloc[:,2:]\n",
    "y = df_train['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=6666)\n",
    "\n",
    "X_smple = df_sampling.iloc[:,2:]\n",
    "y_smple = df_sampling['target']\n",
    "X_train_smple, X_test_smple, y_train_smple, y_test_smple = train_test_split(X_smple, y_smple, test_size=0.3, random_state=66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 LGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold num:1\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttrain's auc: 0.835568\tvalid's auc: 0.822852\n",
      "[2000]\ttrain's auc: 0.868401\tvalid's auc: 0.852864\n",
      "[3000]\ttrain's auc: 0.884656\tvalid's auc: 0.867356\n",
      "[4000]\ttrain's auc: 0.894401\tvalid's auc: 0.875657\n",
      "[5000]\ttrain's auc: 0.900871\tvalid's auc: 0.881049\n",
      "[6000]\ttrain's auc: 0.905744\tvalid's auc: 0.885144\n",
      "[7000]\ttrain's auc: 0.909325\tvalid's auc: 0.888263\n",
      "[8000]\ttrain's auc: 0.912164\tvalid's auc: 0.8906\n",
      "[9000]\ttrain's auc: 0.914421\tvalid's auc: 0.89245\n",
      "[10000]\ttrain's auc: 0.916374\tvalid's auc: 0.893909\n",
      "[11000]\ttrain's auc: 0.917959\tvalid's auc: 0.895066\n",
      "[12000]\ttrain's auc: 0.919378\tvalid's auc: 0.896049\n",
      "[13000]\ttrain's auc: 0.920671\tvalid's auc: 0.896709\n",
      "[14000]\ttrain's auc: 0.921794\tvalid's auc: 0.897166\n",
      "[15000]\ttrain's auc: 0.922837\tvalid's auc: 0.897622\n",
      "[16000]\ttrain's auc: 0.923792\tvalid's auc: 0.89797\n",
      "[17000]\ttrain's auc: 0.924719\tvalid's auc: 0.898186\n",
      "[18000]\ttrain's auc: 0.925611\tvalid's auc: 0.898331\n",
      "[19000]\ttrain's auc: 0.926478\tvalid's auc: 0.89852\n",
      "[20000]\ttrain's auc: 0.927348\tvalid's auc: 0.898684\n",
      "[21000]\ttrain's auc: 0.928187\tvalid's auc: 0.898765\n",
      "Early stopping, best iteration is:\n",
      "[20646]\ttrain's auc: 0.927885\tvalid's auc: 0.898781\n",
      "Fold num:2\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttrain's auc: 0.836187\tvalid's auc: 0.821031\n",
      "[2000]\ttrain's auc: 0.868754\tvalid's auc: 0.852231\n",
      "[3000]\ttrain's auc: 0.884859\tvalid's auc: 0.867075\n",
      "[4000]\ttrain's auc: 0.894538\tvalid's auc: 0.875742\n",
      "[5000]\ttrain's auc: 0.901173\tvalid's auc: 0.881222\n",
      "[6000]\ttrain's auc: 0.906185\tvalid's auc: 0.885352\n",
      "[7000]\ttrain's auc: 0.910016\tvalid's auc: 0.888337\n",
      "[8000]\ttrain's auc: 0.912839\tvalid's auc: 0.890362\n",
      "[9000]\ttrain's auc: 0.915192\tvalid's auc: 0.892069\n",
      "[10000]\ttrain's auc: 0.917116\tvalid's auc: 0.893234\n",
      "[11000]\ttrain's auc: 0.918749\tvalid's auc: 0.894107\n",
      "[12000]\ttrain's auc: 0.920186\tvalid's auc: 0.894781\n",
      "[13000]\ttrain's auc: 0.921421\tvalid's auc: 0.895385\n",
      "[14000]\ttrain's auc: 0.922544\tvalid's auc: 0.895737\n",
      "[15000]\ttrain's auc: 0.923566\tvalid's auc: 0.895983\n",
      "[16000]\ttrain's auc: 0.924559\tvalid's auc: 0.89614\n",
      "[17000]\ttrain's auc: 0.925517\tvalid's auc: 0.896351\n",
      "[18000]\ttrain's auc: 0.926402\tvalid's auc: 0.896489\n",
      "[19000]\ttrain's auc: 0.927298\tvalid's auc: 0.896513\n",
      "[20000]\ttrain's auc: 0.928162\tvalid's auc: 0.896525\n",
      "Early stopping, best iteration is:\n",
      "[19754]\ttrain's auc: 0.927951\tvalid's auc: 0.896573\n",
      "Fold num:3\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttrain's auc: 0.834322\tvalid's auc: 0.824013\n",
      "[2000]\ttrain's auc: 0.867126\tvalid's auc: 0.85569\n",
      "[3000]\ttrain's auc: 0.883496\tvalid's auc: 0.870869\n",
      "[4000]\ttrain's auc: 0.893356\tvalid's auc: 0.879697\n",
      "[5000]\ttrain's auc: 0.900044\tvalid's auc: 0.885672\n",
      "[6000]\ttrain's auc: 0.905015\tvalid's auc: 0.889799\n",
      "[7000]\ttrain's auc: 0.908732\tvalid's auc: 0.892754\n",
      "[8000]\ttrain's auc: 0.911664\tvalid's auc: 0.895046\n",
      "[9000]\ttrain's auc: 0.914069\tvalid's auc: 0.896623\n",
      "[10000]\ttrain's auc: 0.916039\tvalid's auc: 0.897793\n",
      "[11000]\ttrain's auc: 0.917674\tvalid's auc: 0.898605\n",
      "[12000]\ttrain's auc: 0.919102\tvalid's auc: 0.89919\n",
      "[13000]\ttrain's auc: 0.920354\tvalid's auc: 0.899665\n",
      "[14000]\ttrain's auc: 0.921539\tvalid's auc: 0.900078\n",
      "[15000]\ttrain's auc: 0.922571\tvalid's auc: 0.900277\n",
      "[16000]\ttrain's auc: 0.923566\tvalid's auc: 0.900435\n",
      "[17000]\ttrain's auc: 0.924516\tvalid's auc: 0.900508\n",
      "[18000]\ttrain's auc: 0.925426\tvalid's auc: 0.900543\n",
      "[19000]\ttrain's auc: 0.926302\tvalid's auc: 0.900651\n",
      "[20000]\ttrain's auc: 0.927147\tvalid's auc: 0.900604\n",
      "Early stopping, best iteration is:\n",
      "[19062]\ttrain's auc: 0.92636\tvalid's auc: 0.900659\n",
      "Fold num:4\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttrain's auc: 0.834685\tvalid's auc: 0.824253\n",
      "[2000]\ttrain's auc: 0.866725\tvalid's auc: 0.855362\n",
      "[3000]\ttrain's auc: 0.883504\tvalid's auc: 0.871348\n",
      "[4000]\ttrain's auc: 0.893389\tvalid's auc: 0.880173\n",
      "[5000]\ttrain's auc: 0.900071\tvalid's auc: 0.885843\n",
      "[6000]\ttrain's auc: 0.904912\tvalid's auc: 0.889614\n",
      "[7000]\ttrain's auc: 0.908749\tvalid's auc: 0.892404\n",
      "[8000]\ttrain's auc: 0.911672\tvalid's auc: 0.894532\n",
      "[9000]\ttrain's auc: 0.914094\tvalid's auc: 0.896218\n",
      "[10000]\ttrain's auc: 0.916048\tvalid's auc: 0.897423\n",
      "[11000]\ttrain's auc: 0.917713\tvalid's auc: 0.898265\n",
      "[12000]\ttrain's auc: 0.919149\tvalid's auc: 0.899012\n",
      "[13000]\ttrain's auc: 0.920422\tvalid's auc: 0.899491\n",
      "[14000]\ttrain's auc: 0.92159\tvalid's auc: 0.899862\n",
      "[15000]\ttrain's auc: 0.922653\tvalid's auc: 0.900204\n",
      "[16000]\ttrain's auc: 0.923675\tvalid's auc: 0.900427\n",
      "[17000]\ttrain's auc: 0.924637\tvalid's auc: 0.900581\n",
      "[18000]\ttrain's auc: 0.925557\tvalid's auc: 0.900696\n",
      "[19000]\ttrain's auc: 0.926453\tvalid's auc: 0.900721\n",
      "Early stopping, best iteration is:\n",
      "[18809]\ttrain's auc: 0.926284\tvalid's auc: 0.900758\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-b20c915602bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mval_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlgbm_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mtest_pred_lgbm\u001b[0m  \u001b[1;33m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlgbm_test_x\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mfull_pred\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0mtarget_pred\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, pred_parameter)\u001b[0m\n\u001b[0;32m   1788\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1789\u001b[0m             \u001b[0mnum_iteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1790\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_has_header\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_reshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1792\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_leaf_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleaf_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             preds, nrow = self.__pred_for_np2d(data, num_iteration,\n\u001b[1;32m--> 437\u001b[1;33m                                                predict_type)\n\u001b[0m\u001b[0;32m    438\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[1;34m(self, mat, num_iteration, predict_type)\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_parameter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_num_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m             preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[0;32m    505\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_preds\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mout_num_preds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Wrong length for predict results\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Model LGBM \n",
    "def create_model_lgbm(X_train,y_train,X_val=None,y_val=None):\n",
    "    dtrain = lgb.Dataset(X_train,label=y_train)\n",
    "    dval = lgb.Dataset(X_val,label=y_val)\n",
    "    param = {\n",
    "    'bagging_freq': 3,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.1,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 2,  \n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 100,\n",
    "    'num_leaves': 35,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary', \n",
    "    'verbosity': 1\n",
    "    }\n",
    "    if not X_val is None:\n",
    "        valid_sets = (dtrain,dval)\n",
    "        valid_names = ['train','valid']\n",
    "    else:\n",
    "        valid_sets = (dtrain)\n",
    "        valid_names = ['train']\n",
    "    model = lgb.train(param,dtrain,num_boost_round=50000,valid_sets=valid_sets,valid_names=['train','valid'],\n",
    "                      verbose_eval=1000,\n",
    "                     early_stopping_rounds=1000)\n",
    "    return model\n",
    "\n",
    "lgbm_X = X\n",
    "lgbm_y = y\n",
    "lgbm_test_x = X_test\n",
    "lgbm_test_y = y_test\n",
    "val_pred = np.zeros(len(lgbm_X))\n",
    "full_pred = np.zeros(len(X))\n",
    "test_pred_lgbm = np.zeros(len(lgbm_test_y))\n",
    "target_pred = np.zeros(len(df_test))\n",
    "kf = KFold(n_splits=5,random_state=67)\n",
    "for _fold, (trn_idx, val_idx) in enumerate(kf.split(lgbm_X.values, lgbm_y.values)):   \n",
    "        Xtrn, ytrn = lgbm_X.iloc[trn_idx], lgbm_y.iloc[trn_idx]\n",
    "        Xval, y_val = lgbm_X.iloc[val_idx], lgbm_y.iloc[val_idx]\n",
    "        print(\"Fold num:{}\".format(_fold + 1))\n",
    "        clf = create_model_lgbm(Xtrn,ytrn,Xval,y_val)\n",
    "        val_pred[val_idx] = clf.predict(lgbm_X.iloc[val_idx])\n",
    "        test_pred_lgbm  += clf.predict(lgbm_test_x) / kf.n_splits\n",
    "        full_pred += clf.predict(X) / kf.n_splits\n",
    "        target_pred += clf.predict(df_test.iloc[:,1:]) / kf.n_splits\n",
    "    \n",
    "print('Full Training Data Score : ', roc_auc_score(y, full_pred))\n",
    "print('Val CV score : ', roc_auc_score(lgbm_y, val_pred))\n",
    "print('Test CV score : ', roc_auc_score(lgbm_test_y, test_pred_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 60\n",
    "indxs = np.argsort(clf.feature_importance())[:num_features]\n",
    "feature_imp = pd.DataFrame(sorted(zip(clf.feature_importance()[indxs], \n",
    "                                      X.columns[indxs])), columns=['Value','Feature'])\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.barplot(x='Value', y='Feature', data=feature_imp.sort_values(by='Value', ascending=False))\n",
    "plt.title('Top {} LightGBM Features'.format(num_features))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Keras DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.kallbacks import EarlyStopping\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n",
    "\n",
    "def create_model_nn(in_dim, layer_size=120):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer_size, input_dim=in_dim))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(layer_size))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(layer_size))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(layer_size))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics = [auc])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_nn = create_model_nn(X_train.shape[1])\n",
    "callback = EarlyStopping('val_loss', patience=6, verbose=0, mode='auto')\n",
    "history = model_nn.fit(X_train, y_train, \n",
    "                       validation_data = [X_test, y_test], \n",
    "                       epochs=100, batch_size=256, \n",
    "                       verbose=1, callbacks = [callback])\n",
    "\n",
    "target_pred_nn = model_nn.predict(df_test.iloc[:,1:])[:,0]\n",
    "print('\\nNon-Sampled Validation Max score : {}'.format(np.max(history.history['val_auc'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
